
import os, io, re, json
import numpy as np, cv2, streamlit as st, pandas as pd, easyocr
from pdf2image import convert_from_bytes
from app.config import ALLOWED_EXTS, LANG_LIST, DEFAULTS, MAX_FILE_SIZE_MB, PREVIEW_MAX_WIDTH, CITIES_HINT

st.set_page_config(page_title="OCR –¥–æ–≥–æ–≤–æ—Ä ‚Äî —É—Å–∏–ª–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ v26", layout="wide")
st.title("üìÑ OCR: –æ—Ä–∏–≥–∏–Ω–∞–ª vs —É–ª—É—á—à–µ–Ω–∏–µ (v26)")

uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª (PDF/PNG/JPG/TIFF)", type=[e.strip(".") for e in ALLOWED_EXTS])

def _render_image(img, caption=None):
    try:
        st.image(img, caption=caption)
    except:
        st.write(caption or "")
        st.image(img)

def _pdf_to_bgr_pages(data: bytes, dpi: int) -> list:
    pages = convert_from_bytes(data, fmt="png", dpi=dpi)
    return [cv2.cvtColor(np.array(p), cv2.COLOR_RGB2BGR) for p in pages]

def _decode_file_to_bgr_list(file_bytes: bytes, filename: str, dpi: int):
    ext = os.path.splitext(filename)[1].lower()
    if ext == ".pdf":
        return _pdf_to_bgr_pages(file_bytes, dpi)
    arr = np.frombuffer(file_bytes, dtype=np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    return [img] if img is not None else []

def _enhance(img_bgr: np.ndarray, scale: float, denoise_h: int, sharp_amount: float) -> np.ndarray:
    img = img_bgr.copy()
    if abs(scale - 1.0) > 1e-6:
        h, w = img.shape[:2]
        img = cv2.resize(img, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_CUBIC)
    try:
        img = cv2.fastNlMeansDenoisingColored(img, None, h=denoise_h, hColor=denoise_h, templateWindowSize=7, searchWindowSize=21)
    except:
        pass
    try:
        blur = cv2.GaussianBlur(img, (0,0), 1.0)
        img = cv2.addWeighted(img, 1.0 + sharp_amount, blur, -sharp_amount, 0)
    except:
        pass
    return img

def _shrink(rgb_img: np.ndarray, max_w: int = PREVIEW_MAX_WIDTH) -> np.ndarray:
    h, w = rgb_img.shape[:2]
    if w <= max_w:
        return rgb_img
    scale = max_w / float(w)
    return cv2.resize(rgb_img, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)

# --- Text normalization & helpers ---
def _normalize_text(s: str) -> str:
    if not s:
        return ""
    LAT2CYR = str.maketrans({
        "A":"–ê","B":"–í","E":"–ï","K":"–ö","M":"–ú","H":"–ù","O":"–û","P":"–†","C":"–°","T":"–¢","X":"–•","Y":"–£",
        "a":"–∞","e":"–µ","o":"–æ","p":"—Ä","c":"—Å","x":"—Ö","y":"—É"
    })
    out = s.translate(LAT2CYR)
    out = re.sub(r"\bN[¬∞¬∫o–æ]?\s*", "‚Ññ ", out, flags=re.IGNORECASE)
    out = out.replace("‚Äì","-").replace("‚Äî","-")
    out = re.sub(r"\s+", " ", out)
    return out.strip()

def _find_any_date(t: str):
    m = re.search(r"\b(\d{1,2})[.\-/](\d{1,2})[.\-/]((?:19|20)\d{2})\b", t)
    if m:
        dd, mm, yy = m.groups()
        return f"{dd.zfill(2)}.{mm.zfill(2)}.{yy}"
    # textual month (—Ä—É—Å.)
    m = re.search(r'([¬´"]?)(\d{1,2})\1\s+([–ê-–Ø–∞-—èA-Za-z]+)\s+((?:19|20)\d{2})', t)
    if m:
        d = m.group(2); mon = m.group(3).lower(); y = m.group(4)
        RU = {"—è–Ω–≤–∞—Ä":"01","—Ñ–µ–≤—Ä–∞–ª":"02","–º–∞—Ä—Ç":"03","–∞–ø—Ä–µ–ª":"04","–º–∞":"05","–∏—é–Ω":"06","–∏—é–ª":"07","–∞–≤–≥—É—Å—Ç":"08","—Å–µ–Ω—Ç—è–±—Ä":"09","–æ–∫—Ç—è–±—Ä":"10","–Ω–æ—è–±—Ä":"11","–¥–µ–∫–∞–±—Ä":"12"}
        mm = None
        for k,v in RU.items():
            if mon.startswith(k): mm = v; break
        if mm:
            return f"{d.zfill(2)}.{mm}.{y}"
    return None

def _window_after_kw(t: str, kw_regex: str, max_len: int = 100):
    m = re.search(kw_regex + r"\s*[:\-]?\s*([^\n]{1,%d})" % max_len, t, re.IGNORECASE)
    return m.group(1).strip() if m else None

def _find_city(t: str):
    # 1) explicit known cities
    for city in CITIES_HINT:
        if re.search(rf"\b{re.escape(city)}\b", t, re.IGNORECASE):
            return city
    # 2) pattern "DAP <City>" or "–≤ –≥. <City>"
    m = re.search(r"\bDAP\s+([A-Z–ê-–Ø–Å][A-Za-z–ê-–Ø–∞-—è–Å—ë\- ]{2,30})\b", t)
    if m: return m.group(1).strip()
    m = re.search(r"\b–≥\.?\s*([A-Z–ê-–Ø–Å][A-Za-z–ê-–Ø–∞-—è–Å—ë\- ]{2,30})\b", t)
    if m: return m.group(1).strip()
    # 3) pattern "<City>; –†–µ—Å–ø—É–±–ª–∏–∫–∞"
    m = re.search(r"\b([A-Z–ê-–Ø–Å][A-Za-z–ê-–Ø–∞-—è–Å—ë\- ]{2,30})\s*;\s*–†–µ—Å–ø—É–±–ª–∏–∫–∞", t)
    if m: return m.group(1).strip()
    return None



def _extract_fields(text: str):
    """
    Strict extraction per user's rules, robust to spacing.
    ALWAYS returns the exact schema of 14 fields.
    """
    REQUIRED_COLS = ["–ù–æ–º–µ—Ä –¥–æ–≥–æ–≤–æ—Ä–∞","–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞","–ì–æ—Ä–æ–¥","–ü—Ä–æ–¥–∞–≤–µ—Ü","–ü–æ–∫—É–ø–∞—Ç–µ–ª—å",
                     "–ò–ò–ù/–ë–ò–ù –∫–ª–∏–µ–Ω—Ç–∞","IBAN","–ù–æ–º–µ—Ä –∫–∞—Ä—Ç—ã","–°—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞","–í–∞–ª—é—Ç–∞",
                     "–°—Ä–æ–∫ —Å","–°—Ä–æ–∫ –ø–æ","–ë–ò–ö –±–∞–Ω–∫–∞","–ò–ò–ö –±–∞–Ω–∫–∞"]
    out = {k: None for k in REQUIRED_COLS}
    diag = {}

    t = text or ""
    t = re.sub(r"\s+", " ", t)
    t = re.sub(r"–î\s*–û\s*–ì\s*–û\s*–í\s*–û\s*–†", "–î–û–ì–û–í–û–†", t, flags=re.IGNORECASE)
    t = re.sub(r"\bN[¬∞¬∫o–æ]?\s*", "‚Ññ ", t, flags=re.IGNORECASE)
    t = t.replace("‚Äì","-").replace("‚Äî","-").strip()

    m = re.search(r"–î–û–ì–û–í–û–†\s*‚Ññ\s*([A-Za-z–ê-–Ø–∞-—è0-9/_\-]+)", t)
    if m:
        out["–ù–æ–º–µ—Ä –¥–æ–≥–æ–≤–æ—Ä–∞"] = m.group(1); diag["–ù–æ–º–µ—Ä –¥–æ–≥–æ–≤–æ—Ä–∞"] = "rx:–î–û–ì–û–í–û–† ‚Ññ"

    m = re.search(r"–î–û–ì–û–í–û–†\s*‚Ññ\s*[A-Za-z–ê-–Ø–∞-—è0-9/_\-]+\s*–æ—Ç\s*(\d{1,2}[.\-/]\d{1,2}[.\-/]\d{2,4})", t)
    if m:
        out["–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"] = m.group(1); diag["–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"] = "rx:‚Ññ ... –æ—Ç <–¥–∞—Ç–∞>"

    city = None
    m = re.search(r"\bDAP\s+([A-Z–ê-–Ø–Å][A-Za-z–ê-–Ø–∞-—è–Å—ë\- ]{2,30})\b", t)
    if m:
        import re as _re
        city = _re.split(r"\s+(?=—Å–æ–≥–ª–∞—Å–Ω–æ\b)", m.group(1))[0].strip()
    if not city:
        m = re.search(r"\b([A-Z–ê-–Ø–Å][A-Za-z-–ê-–Ø–∞-—è–Å—ë\- ]{2,30})\s*;\s*–†–µ—Å–ø—É–±–ª–∏–∫–∞\b", t)
        if m: city = m.group(1).strip()
    if not city:
        m = re.search(r"\b–≥\.?\s*([A-Z–ê-–Ø–Å][A-Za-z-–ê-–Ø–∞-—è–Å—ë\- ]{2,30})\b", t)
        if m: city = m.group(1).strip()
    if city:
        out["–ì–æ—Ä–æ–¥"] = city; diag["–ì–æ—Ä–æ–¥"] = "pattern"

    m = re.search(r"–ü—Ä–æ–¥–∞–≤–µ—Ü\s*[:\-]\s*([^\n;:]{3,100})", t, re.IGNORECASE)
    if m:
        out["–ü—Ä–æ–¥–∞–≤–µ—Ü"] = m.group(1).strip(); diag["–ü—Ä–æ–¥–∞–≤–µ—Ü"] = "kw:–ü—Ä–æ–¥–∞–≤–µ—Ü:"

    m = re.search(r"(?:–ü–æ–∫—É–ø–∞—Ç–µ–ª—å|–ö–ª–∏–µ–Ω—Ç)\s*[:\-]\s*([^\n;:]{3,100})", t, re.IGNORECASE)
    if m:
        out["–ü–æ–∫—É–ø–∞—Ç–µ–ª—å"] = m.group(1).strip(); diag["–ü–æ–∫—É–ø–∞—Ç–µ–ª—å"] = "kw:–ü–æ–∫—É–ø–∞—Ç–µ–ª—å:/–ö–ª–∏–µ–Ω—Ç:"

    m = re.search(r"–ò–ò–ù\s*[:‚Ññ]?\s*([\d\s]{12,18})", t)
    if not m:
        m = re.search(r"–ë–ò–ù\s*[:‚Ññ]?\s*([\d\s]{12,18})", t)
    if m:
        clean = re.sub(r"\D", "", m.group(1))
        if len(clean)==12:
            out["–ò–ò–ù/–ë–ò–ù –∫–ª–∏–µ–Ω—Ç–∞"] = clean; diag["–ò–ò–ù/–ë–ò–ù –∫–ª–∏–µ–Ω—Ç–∞"] = "rx:–ò–ò–ù/–ë–ò–ù"

    m = re.search(r"\bKZ\s*\d{2}\s*[0-9A-Z]{3}\s*\d{13}\b", t, re.IGNORECASE)
    if m:
        out["IBAN"] = re.sub(r"\s+","", m.group(0)).upper(); diag["IBAN"] = "rx:KZ IBAN"

    for m in re.finditer(r"\b(?:\d[ \-]?){13,19}\b", t):
        digits = re.sub(r"\D", "", m.group(0))
        if len(digits)==16:
            out["–ù–æ–º–µ—Ä –∫–∞—Ä—Ç—ã"] = f"{digits[:4]} {digits[4:8]} {digits[8:12]} {digits[12:16]}"
            diag["–ù–æ–º–µ—Ä –∫–∞—Ä—Ç—ã"] = "rx:16digits"; break

    m = re.search(r"(–°—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞|–û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –¥–æ–≥–æ–≤–æ—Ä–∞|–û–±—â–∞—è —Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞|–°—Ç–æ–∏–º–æ—Å—Ç—å –¥–æ–≥–æ–≤–æ—Ä–∞)[^\d]{0,40}([\d\s.,]+)", t, re.IGNORECASE)
    if m:
        val = re.sub(r"[\s,]", "", m.group(2))
        try:
            out["–°—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"] = float(val); diag["–°—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"] = "rx:amount"
        except:
            pass

    m = re.search(r"–í–∞–ª—é—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞\s*[:\-]?\s*([A-Za-z–ê-–Ø–∞-—è–Å—ë]+(?:\s+[A-Za-z–ê-–Ø–∞-—è–Å—ë]+)?)", t, re.IGNORECASE)
    if m:
        cur = m.group(1).strip().lower()
        if "—Ç–µ–Ω–≥–µ" in cur or "—Ç–Ω–≥" in cur: cur = "KZT"
        elif "—Ä—É–±" in cur: cur = "RUB"
        elif "–¥–æ–ª–ª–∞—Ä" in cur: cur = "USD"
        elif "–µ–≤—Ä–æ" in cur: cur = "EUR"
        out["–í–∞–ª—é—Ç–∞"] = cur.upper() if len(cur) <= 4 else cur
        diag["–í–∞–ª—é—Ç–∞"] = "kw:–í–∞–ª—é—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"

    m_list = list(re.finditer(r"\b–ø–æ\s*(\d{1,2}[.\-/]\d{1,2}[.\-/]\d{2,4})", t, re.IGNORECASE))
    if m_list:
        out["–°—Ä–æ–∫ –ø–æ"] = m_list[-1].group(1); diag["–°—Ä–æ–∫ –ø–æ"] = "rx:–ø–æ <–¥–∞—Ç–∞>"

    if out["–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"]:
        out["–°—Ä–æ–∫ —Å"] = out["–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"]; diag["–°—Ä–æ–∫ —Å"] = "copy:–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"

    return out, diag



def _to_xlsx_bytes(row: dict):
    cols = ["–ù–æ–º–µ—Ä –¥–æ–≥–æ–≤–æ—Ä–∞","–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞","–ì–æ—Ä–æ–¥","–ü—Ä–æ–¥–∞–≤–µ—Ü","–ü–æ–∫—É–ø–∞—Ç–µ–ª—å","–ò–ò–ù/–ë–ò–ù –∫–ª–∏–µ–Ω—Ç–∞","IBAN","–ù–æ–º–µ—Ä –∫–∞—Ä—Ç—ã","–°—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞","–í–∞–ª—é—Ç–∞","–°—Ä–æ–∫ —Å","–°—Ä–æ–∫ –ø–æ","–ë–ò–ö –±–∞–Ω–∫–∞","–ò–ò–ö –±–∞–Ω–∫–∞"]
    row2 = {k: row.get(k) for k in cols}
    df = pd.DataFrame([row2], columns=cols)
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as w:
        df.to_excel(w, index=False, sheet_name="result")
    bio.seek(0)
    return bio.getvalue()

if uploaded is not None:
    raw = uploaded.read()
    if not raw:
        st.error("–§–∞–π–ª –ø—É—Å—Ç"); st.stop()
    if len(raw) > MAX_FILE_SIZE_MB*1024*1024:
        st.error("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π"); st.stop()

    pages = _decode_file_to_bgr_list(raw, uploaded.name, DEFAULTS["pdf_dpi"])
    if not pages:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç"); st.stop()

    st.subheader("–í—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: –û—Ä–∏–≥–∏–Ω–∞–ª vs –£–ª—É—á—à–µ–Ω–æ")
    for i, p in enumerate(pages, start=1):
        enh = _enhance(p, DEFAULTS["scale"], DEFAULTS["denoise_h"], DEFAULTS["sharp_amount"])
        c1, c2 = st.columns(2)
        with c1: _render_image(_shrink(cv2.cvtColor(p, cv2.COLOR_BGR2RGB)), f"–°—Ç—Ä. {i} ‚Äî –û—Ä–∏–≥–∏–Ω–∞–ª")
        with c2: _render_image(_shrink(cv2.cvtColor(enh, cv2.COLOR_BGR2RGB)), f"–°—Ç—Ä. {i} ‚Äî –£–ª—É—á—à–µ–Ω–æ")

    st.subheader("–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ (EasyOCR)")
    with st.spinner("OCR..."):
        reader = easyocr.Reader(LANG_LIST)
        parts = []
        for p in pages:
            enh = _enhance(p, DEFAULTS["scale"], DEFAULTS["denoise_h"], DEFAULTS["sharp_amount"])
            res = reader.readtext(enh, detail=1, paragraph=False)
            for _, txt, conf in res:
                t = (txt or "").strip()
                if t and (conf or 0) >= DEFAULTS["ocr_threshold"]:
                    parts.append(t)
        full = "\n".join(parts)

    st.text_area("–¢–µ–∫—Å—Ç (>= –ø–æ—Ä–æ–≥–∞)", full, height=220)

    fields, diag = _extract_fields(full)
    st.subheader("–ö–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")
    st.json(fields)
    with st.expander("–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π", expanded=False):
        st.json(diag)

    xlsx_bytes = _to_xlsx_bytes(fields)
    st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å XLSX", xlsx_bytes, file_name="result.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    json_bytes = json.dumps(fields, ensure_ascii=False, indent=2).encode("utf-8")
    st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å JSON", json_bytes, file_name="result.json", mime="application/json")
else:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: –º–∞—Å—à—Ç–∞–± 1.5√ó, —à—É–º 15, —Ä–µ–∑–∫–æ—Å—Ç—å 2.0, –ø–æ—Ä–æ–≥ 0.85, DPI 300.")
